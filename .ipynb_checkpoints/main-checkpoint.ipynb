{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84354767-b851-46dc-814a-3c03b0b0c48d",
   "metadata": {},
   "source": [
    "TODO\n",
    "- need to duplicate into script\n",
    "- need to locate the codon dictionaries from the main_package directory\n",
    "- stop codon variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d690c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import argparse\n",
    "from Bio.SeqUtils import GC\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import random\n",
    "import main_package # my package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0edf1bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--vect VECT] [--codon_table CODON_TABLE]\n",
      "                             [--homo_len HOMO_LEN] [--primer_len PRIMER_LEN]\n",
      "                             [--melt_temp MELT_TEMP]\n",
      "                             [--rev_melt_temp REV_MELT_TEMP]\n",
      "                             [--syn_snp SYN_SNP] [--out_dir OUT_DIR]\n",
      "                             protein up wt down\n",
      "ipykernel_launcher.py: error: the following arguments are required: up, wt, down\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/alignparse-environment/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3449: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "### SKIP until this is scripted\n",
    "# parse arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"protein\", help=\"Name of protein sequence\", type=str)\n",
    "parser.add_argument(\"up\", help=\"Up: 30bp 5' of sequence\", type=str)\n",
    "parser.add_argument(\"wt\", help=\"WT: sequence of interest\", type=str)\n",
    "parser.add_argument(\"down\", help=\"Down: 30bp 3' of sequence \", type=str)\n",
    "parser.add_argument(\"--vect\", help=\"Vect: sequence of interest in vector\", type=str, default=False)\n",
    "parser.add_argument(\"--codon_table\", help=\"Specify codon table to use\", type=str, default='Standard')\n",
    "parser.add_argument(\"--homo_len\", help=\"Length of homology arm in fwd primer\", type=int, default=20)\n",
    "parser.add_argument(\"--primer_len\", help=\"Ideal max length of primers\", type=int, default=60)\n",
    "parser.add_argument(\"--melt_temp\", help=\"Melting temp of fwd primer\", type=int, default=50)\n",
    "parser.add_argument(\"--rev_melt_temp\", help=\"Melting temp of rev primer\", type=int, default=55)\n",
    "parser.add_argument(\"--syn_snp_rate\", help=\"Percentage of synonymous SNPs 0-1\", type=float, default=.05)\n",
    "parser.add_argument(\"--stop_rate\", help=\"Percentage of stop codon SNPs, default = keep 10% of stop SNPs\", type=float, default=.10)\n",
    "parser.add_argument(\"--rng_seed\", help=\"Set seed for repoducibly selecting synonymous codon sites\", type=int, default=42)\n",
    "parser.add_argument(\"--out_dir\", help=\"Local output directory e.g. 'data/'\", type=str, default=.05)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac45e16-75b2-4207-9f31-2a015d090d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate iupac codon dictionaries to generate doped primers\n",
    "missense_dict, synonymous_dict, no_stop_dict, no_stop_syn_dict =  main_package.codon_table.iupac_codon_dicts()\n",
    "\n",
    "# generate yeast synonymous codon dictionary (no missense variants)\n",
    "yeast_synonymous_dict = main_package.codon_table.synonymous_yeast_codons_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ed0c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .gb loop practice: MESSY\n",
    "wt_input = 'k3l_test.gb'\n",
    "vector_input = None\n",
    "\n",
    "# check for vector file\n",
    "wt_file = SeqIO.read(wt_input, 'genbank')\n",
    "if vector_input == None:\n",
    "    vector_input = wt_input\n",
    "vector_file = SeqIO.read(vector_input, 'genbank')\n",
    "    \n",
    "wt_seq = str(wt_file.seq.upper())\n",
    "vector_seq = str(vector_file.seq.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8294e447-8d42-45d7-991f-4ae9b1eaf188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656\n",
      "1923\n"
     ]
    }
   ],
   "source": [
    "# get start and stop of gene for codon positions\n",
    "for feature in wt_file.features:\n",
    "    if feature.type == 'gene':\n",
    "        gene_start = feature.location.start.position\n",
    "        gene_end = feature.location.end.position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c22b4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SANITY CHECKS (make an error check module?)\n",
    "\n",
    "# check that wt and vector files are equal in length\n",
    "if len(wt_seq) != len(vector_seq):\n",
    "    print('Error: WildType and Vector GenBank sequences are not of equal length')\n",
    "    #break\n",
    "    \n",
    "# check for -20 bp homology\n",
    "\n",
    "# check that the strand is going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74cc27ed-1256-44c2-8b54-4eabcee29f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcode test variables\n",
    "homo_len = 20 ### args.homo_len\n",
    "rev_melt_temp = 55 ### args.rev_melt_temp\n",
    "primer_len = 60 ### args.primer_len\n",
    "melt_temp = 50 ### args.melt_temp\n",
    "syn_snp_rate = .05 ### args.syn_snp_rate\n",
    "stop_rate = .1 ### args.stop_rate\n",
    "output_prefix = 'k3l_test' # maybe have a prefix for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57df82ff-a49c-4075-8691-c8284c2528b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### loop through the window\n",
    "\n",
    "# create empty dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# set RNG with seed \n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# this needs to be fixed (user input? yaml?)\n",
    "targ_windows = ['window_1', 'window_2', 'window_3']\n",
    "\n",
    "# setup .fa output, truncate if file exists\n",
    "file = open(f\"{output_prefix}.fa\",'w+')\n",
    "\n",
    "for feature in wt_file.features:\n",
    "    if feature.type not in targ_windows:\n",
    "        continue\n",
    "    \n",
    "    # START LOOP: CHANGE THIS\n",
    "    win_list = []\n",
    "    homo_list = []\n",
    "    rev_primer_list = []\n",
    "    fwd_primer_list = []\n",
    "    mut_windows_list = []\n",
    "    mut_name_list = []\n",
    "    full_window_list = []\n",
    "    full_name_list = []\n",
    "    full_primer_list = []\n",
    "    \n",
    "    start_index = feature.location.start.position\n",
    "    window_end = feature.location.end.position\n",
    "    \n",
    "    # loop for each sub_window\n",
    "    sub_window_n = 1\n",
    "    while start_index < window_end: # this could be an issue to toggle\n",
    "        data_dict = {}\n",
    "        data_dict['start_index'] = start_index\n",
    "        data_dict['sub_window_name'] = {str(feature.type)}-{sub_window_n}\n",
    "        \n",
    "        # 1. homology arm\n",
    "        # INPUT: data dictionary, args (homo_len)\n",
    "        # OUTPUT: data dictionary\n",
    "        homology_arm = vector_seq[start_index - homo_len:start_index] ### args.homo_len\n",
    "        data_dict['homology_arm'] = homology_arm\n",
    "        \n",
    "        # 2. reverse primer\n",
    "        # INPUT: data dictionary\n",
    "        # OUTPUT: data dictionary\n",
    "        reverse_seq = str(Seq(vector_seq[:start_index]).reverse_complement())\n",
    "        reverse_primer = reverse_seq[:15]\n",
    "        while mt.Tm_NN(reverse_primer) < rev_melt_temp: ### args.rev_melt_temp\n",
    "            reverse_primer = reverse_seq[:len(reverse_primer)+1] ### args.rev_melt_temp\n",
    "        data_dict['reverse_primer'] = reverse_primer\n",
    "        \n",
    "        reverse_primer_name = f'rev_{str(feature.type)}-{sub_window_n}'\n",
    "        data_dict['reverse_primer_name'] = reverse_primer_name\n",
    "        \n",
    "        # 3. forward primer\n",
    "        # INPUT: data dictionary, start index\n",
    "        # OUTPUT: \n",
    "        primer_end = start_index + (primer_len - homo_len) ### args.primer_len homo_len\n",
    "        if primer_end > window_end:\n",
    "            primer_end == window_end\n",
    "        \n",
    "        primer_start = primer_end - 15\n",
    "        forward_primer = vector_seq[primer_start:primer_end]\n",
    "\n",
    "        while mt.Tm_NN(forward_primer) < melt_temp: ### args.melt_temp\n",
    "            primer_start -= 1\n",
    "            forward_primer = vector_seq[primer_start:primer_end]\n",
    "\n",
    "        # check if the primer is > 28bp\n",
    "        if len(forward_primer) > (primer_len - homo_len - 12): ### args.primer_len, homo_len\n",
    "            # fix mut window to 12, make a long primer\n",
    "            primer_start = start_index + 12\n",
    "            primer_end = primer_start + 15\n",
    "            forward_primer = vector_seq[primer_start:primer_end]\n",
    "            while True:\n",
    "                forward_primer = vector_seq[primer_start:primer_end]\n",
    "                if mt.Tm_NN(forward_primer) > melt_temp and forward_primer.upper().count('G') + forward_primer.upper().count('C') > 8: ### args.melt_temp\n",
    "                    break\n",
    "                else:\n",
    "                    primer_end += 1\n",
    "        \n",
    "        # even-out the primer length to accomodate codons\n",
    "        else:\n",
    "            # add or subtract a bp from the fwd primer to get mut_window in frame\n",
    "            if (primer_start - start_index)%3 == 2:\n",
    "                primer_start += 1\n",
    "                forward_primer = vector_seq[primer_start:primer_end]\n",
    "\n",
    "            elif (primer_start - start_index)%3 == 1:\n",
    "                primer_start -= 1\n",
    "                forward_primer = vector_seq[primer_start:primer_end]\n",
    "\n",
    "        if primer_start > window_end:\n",
    "            # make the last fwd primer\n",
    "            primer_start = window_end\n",
    "            primer_end = primer_start+15\n",
    "            forward_primer = vector_seq[primer_start:primer_end]\n",
    "            while mt.Tm_NN(forward_primer) < melt_temp:\n",
    "                primer_end += 1\n",
    "                forward_primer = vector_seq[primer_start:primer_end]\n",
    "        data_dict['forward_primer'] = forward_primer\n",
    "        \n",
    "        # 4. variant window\n",
    "        # INPUT: data dictionary, .tsv output, .fa output\n",
    "        # OUTPUT: dataframe, .fa file lines\n",
    "        mut_len = (primer_start) - start_index\n",
    "        mut_end = start_index + mut_len\n",
    "\n",
    "        def codons_list(seq):\n",
    "            return [seq[i:i+3] for i in range(0, len(seq), 3)]\n",
    "        \n",
    "        # removing mis_list and syn_list\n",
    "        wt_list = codons_list(wt_seq[start_index:mut_end])\n",
    "        vect_list = codons_list(vector_seq[start_index:mut_end])\n",
    "\n",
    "        # generate synonymous vector codon list (top 2 codons for yeast)\n",
    "        synonymous_win = [yeast_synonymous_dict[i].lower() for i in vect_list]\n",
    "        \n",
    "        # generate iupac missense codons list (with synonymous codons)  \n",
    "        doped_codons = []\n",
    "        for i, wt_codon in enumerate(wt_list):            \n",
    "            syn_bool = rng.choice([True, False], p=[syn_snp_rate, 1-syn_snp_rate]) ### args.syn_snp_rate\n",
    "            data_dict['synonymous_codons'] = syn_bool\n",
    "            \n",
    "            no_stop_bool = rng.choice([True, False], p=[stop_rate, 1-stop_rate]) ### args.stop_rate\n",
    "            data_dict['no_stop_codons'] = no_stop_bool\n",
    "            # missense_dict, synonymous_dict, no_stop_dict, no_stop_syn_dict\n",
    "            if syn_bool and no_stop_bool:\n",
    "                # use no_stop_syn_dictionary\n",
    "                doped_codons.append(no_stop_syn_dict[wt_codon])\n",
    "            elif syn_bool and not no_stop_bool:\n",
    "                # use synonymous_dictionary\n",
    "                doped_codons.append(synonymous_dict[wt_codon])\n",
    "            elif no_stop_bool and not syn_bool: \n",
    "                # use no_stop_dict\n",
    "                doped_codons.append(no_stop_dict[wt_codon])\n",
    "            else:\n",
    "                # use missense dict\n",
    "                doped_codons.append(missense_dict[wt_codon])\n",
    "        \n",
    "        # generate the mut primer and all info\n",
    "        for i, iupac_list in enumerate(doped_codons):\n",
    "            aa_position = int((((start_index-gene_start)/3)+1)+i)\n",
    "            for iupac_codon in iupac_list:\n",
    "\n",
    "                codon_sub = wt_list[i] + str(aa_position) + iupac_codon\n",
    "                variant_win = ''.join(synonymous_win[:i] + [iupac_codon] + synonymous_win[i+1:])\n",
    "                primer_name = f'{str(feature.type)}-{sub_window_n}_{codon_sub}'\n",
    "                primer = homology_arm + variant_win + forward_primer\n",
    "                \n",
    "                # drop iupac_codon into sub_window\n",
    "                sub_window = ''.join(synonymous_win[:i] + [iupac_codon] + synonymous_win[i+1:])\n",
    "                full_primer = homology_arm + sub_window + forward_primer\n",
    "                \n",
    "                dict_keys = ['name','codon_sub','wt','position','iupac', 'sub_window', 'primer']\n",
    "                dict_values = [primer_name, codon_sub, wt_list[i], aa_position, iupac_codon, sub_window, full_primer]\n",
    "                for (key,value) in zip(dict_keys,dict_values):\n",
    "                    data_dict[key] = value\n",
    "\n",
    "                # append values to dataframe\n",
    "                df = df.append(data_dict, ignore_index=True)\n",
    "                \n",
    "                # write out to .fa\n",
    "                file.writelines([f\">{primer_name}\\n\", f\"{full_primer}\\n\"])\n",
    "     \n",
    "        # reset the start index for the next mini-window\n",
    "        start_index = primer_start\n",
    "        sub_window_n += 1  \n",
    "        \n",
    "file.close()\n",
    "\n",
    "# polish dataframe\n",
    "df['position'] = df['position'].astype(int)\n",
    "df.drop(columns=['start_index'], inplace=True)\n",
    "\n",
    "df['forward_primer_tm'] = df['forward_primer'].apply(lambda x: mt.Tm_NN(x)).round(1)\n",
    "df['forward_primer_gc'] = df['forward_primer'].apply(GC).round(1)\n",
    "df['forward_primer_len'] = df['forward_primer'].str.len()\n",
    "\n",
    "df['reverse_primer_tm'] = df['reverse_primer'].apply(lambda x: mt.Tm_NN(x)).round(1)\n",
    "df['reverse_primer_gc'] = df['reverse_primer'].apply(GC).round(1)\n",
    "df['reverse_primer_len'] = df['reverse_primer'].str.len()\n",
    "\n",
    "cols = ['name','sub_window_name','wt','position','iupac','codon_sub','synonymous_codons','no_stop_codons','primer','homology_arm','sub_window','forward_primer','forward_primer_tm','forward_primer_gc','forward_primer_len','reverse_primer','reverse_primer_name','reverse_primer_tm','reverse_primer_gc','reverse_primer_len']\n",
    "df = df[cols]\n",
    "\n",
    "# save dataframe as .tsv\n",
    "df.to_csv(f'{output_prefix}.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca397e-cfc5-4c72-bf0a-de554217481d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alignparse-environment",
   "language": "python",
   "name": "alignparse-environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
